# Home
I'm Yashovardhan Srivastava, a recent engineering undergraduate(2025) with a strong passion for building, researching and sharing knowledge. I write extensively, both technical and non-technical, so do check them out. Here are my [technical blogs](./blogs.html), and here is my unofficial [diary](./diary.html). 

Beyond that, If you want to contact me, here are my [socials](./contact.html)

## Should you hire me?
Short Answer: Yes. If you need convincing, read the small blurb below about me. Here's my [resume](https://drive.google.com/file/d/1lH9E7mD-rP0Qi73ufAQQKIh5qsLr05lu/view?usp=sharing) if you prefer it that way:

- **High Agency :** This is the most important skill for me. I take ownership of everything I work on, and can go great lengths to make it happen if I believe in the project. I have a great blend of both research and engineering skills, so if I commit to a project, I see it through.

- **Team Player :** I have been part of, and lead teams at college level in ML/AI domain. I have successfully conducted various workshops, and hosted events(details in this page) and collaborated with engineers and researchers. I understand teamwork, and know how to maximize its impact.
    
- **Experience :** I have experience in both academia and research setting, and I'm pretty comfortable with conducting independent research(with little pushes in the right direction working best). I've worked in multiple fintech startups to help build their products from 1 to 100 and I've also built a machine translation system(Transformer based) for low-resourced languages during my research internship. I'm well versed in programming and never shy away from learning things I'm unaware of.

- **Thinking Fast and Slow :** I thrive in both "short term high impact projects" and "long term research intensive work". My self-motivated open source projects have been recognized and appreciated by community as well(see next point). I believe I'm effective in tackling complex challenges.

- **Quantifiable work :** I am a [2x Kaggle Expert](https://www.kaggle.com/yashsrivastava51213), created popular Python packages and kernels( which have received appreciation from [Kaggle](https://twitter.com/Yaaaaaashhh/status/1676593869931126786) as well). I have also made open-source projects that have been praised on [HN](https://news.ycombinator.com/item?id=38697922), [GitHub](https://github.com/yash-srivastava19), [Twitter](https://x.com/tailwiinder/status/1759527294287356177?s=20) (multiple instances on Twitter).   

If you'd rather skip the details, here's my [resume](https://drive.google.com/file/d/1lH9E7mD-rP0Qi73ufAQQKIh5qsLr05lu/view?usp=sharing). Please feel free to reach out to me over my [socials](./contact.html) if you feel I would be good fit for your organization. I would love to connect and chat more! 

## Projects üß∞
Here I'll pin some of my favorite projects, more on the research üë®‚Äçüî¨ side(Feel free to critique me on this(and try to contribute if possible :) ) :

  - [**REALBT**](https://github.com/yash-srivastava19/REALBT) (Looking for contributors) : REALBT is a simple, effective backtesting engine written in pure python.
    
  - [**Arrakis**](https://github.com/yash-srivastava19/arrakis) (Looking for contributors) : Arrakis is a library to conduct, track and visualize mechanistic interpretability experiments. 28+ stars on Github ; 250+ monthly PyPi downloads.
    
  - [**Deeprobe**](https://github.com/yash-srivastava19/deeprobe) (Looking for ideas) : Deeprobe is a study to understand feature importance and pattern undderstaing in Sparse Autoencoders using Monte Carlo Tree Search.
       
  - [**SAE Macaronic Languages**](https://github.com/yash-srivastava19/sae-macaronic-analysis) : Understand whether language models learn words beyond language barriers, a study in Mechanistic Interpretability.

  - [**Secure BPE**](https://github.com/yash-srivastava19/sec_bpe) (Work in Progress) : A modified, secure version of Byte Pair Encoding algorithm.
    
  - [**Collaborative Debating**](https://github.com/yash-srivastava19/collaborative-debating) (Work in Progress) : A hacky implementation of the paper "Improving Factuality and Reasoning in Language Models through Multiagent Debate".
    
  - [**NEAT-JAX**](https://github.com/yash-srivastava19/NEAT-JAX) (Working 
 on PR) : An implementation of Neuroevolution of Augmented Topologies Algorithm in JAX which is compatible with EvoJAX. 14+ Github stars ; Multiple PRs
     
  - [**Nexus Theory**](https://github.com/yash-srivastava19/nexus-theory) : Can we really trust our human-ness for the messages that we send into the cosmos? Nexus theory is a gamified version to understand machine learning interpretability using Large Language Models.

  -  [**Elixr**](https://github.com/yash-srivastava19/Elixir) : Elixr an autograd library using Complex Numbers similar to Pytorch. 3+ Github stars ; Multiple PRs

  -  [**Attention Free Revolution**](https://github.com/yash-srivastava19/attention-free-revolution) : Developed *Leviathan* architectures, and alternate to Transformer architecture using a modified attention scores, taking inspiration from signal processing. 7+ Github stars

  -  [**P-GLAm**](https://github.com/yash-srivastava19/P-GLAm) : P-GLAm is a random thought experiment on Infinite Monkey Theorem. In this, I developed a GPT-2 inspired Large Language Model which aims to test the arithmetic correctness.

Here I'll pin some of my favorite projects, more on the development üíª side. Feedback is always appreciated for projects like these.: 

  - [**PySlides**](https://github.com/yash-srivastava19/py_slides): PySlides is terminal based application that converts markdown into slides that can be presented from the terminal.
  
  - [**Devsidian**](https://github.com/yash-srivastava19/devsidian-a2c05a04)(Lovable Project) : Log your developement journey using Devsidian. Made using Lovable for personal use.
     
  - [**Snappyr**](https://github.com/yash-srivastava19/snappyr) : Setup Python Projects Blazingly Fast, and work on things that matter. No External Dependencies. 
     
  - [**Dynamo**](https://github.com/yash-srivastava19/Dynamo) : Dynamo is a Python/Rust implementation of a load balancer and autoscaler for MySQL web tier. 
  
  - [**Safe SQL**](https://github.com/yash-srivastava19/safe_sql) : Safe SQL provides sanity checks for common DB pitfalls(so you don't delete prod DB) ; available as a python package(CLI included). 300+ monthly PyPI Downloads.
  
  - [**Stock Tank**](https://github.com/yash-srivastava19/stock-tank) : End to End ML pipeline to predict stock prices(upto 30 days). Automate retraining, evals and more(Github Actions). Streamlit Web App available as well.  
  
  - [**Gym Tunes**](https://github.com/yash-srivastava19/gym_tunes) : GymTunes is a simple AI agent that schedules a random playlist into your GCalendar based on your vibe. 
  
  - [**AI GF**](https://github.com/yash-srivastava19/ai_gf) : A small weekend project that through which you can create a virtual girlfriend(not made for imitation, but for learning)
  
  - [**Synapse**](https://github.com/yash-srivastava19/Synapse) : Synapse is hackernews-type platform that can be used by any community as a forum. Tried making this for my college, but need more inspiration.
  
  - [**Pandora**](https://github.com/yash-srivastava19/pandora) : Pandora is domain agnostic framework for case study generation and solving.
    
  - [**Verizon**](https://github.com/yash-srivastava19/verizon) : A Git like version control system, from scratch, in Python, spelled out.
    
  - [**YeetCode**](https://github.com/yash-srivastava19/yeetcode) : YeetCode is a sassy version of Python made for all GenZ people. The aim is to create a new programming language which is bussin'.

  - [**Blaze**](https://github.com/yash-srivastava19/blaze) : Developed a RAG(Retrieval Augmentation Generation) system by using Cohere LLM and Metaphor as a part of recruitement process for Metaphor, which is made using Langchain, Chainlit and deployed on Huggingface. 8+ Github stars.
  
  - [**CodeSmith**](https://github.com/yash-srivastava19/CodeSmith) : Developed a ChatGPT-inspired chatbot trained on a Python programming problems on custom created dataset, made using Langchain, and deployed on Huggingface.

  - [**Alzhemist**](https://github.com/yash-srivastava19/Alzhemist) : One of the first projects that got me in to the world of Attention. A Deep Learning Model to see which classifies Brain MRI on the basis of the dementia (AD). The images are classified as follows - Mildly Demented, Moderate Demented, Non Demented, Very Mild Demented.
    
  - [**Maxwell**](https://github.com/yash-srivastava19/Maxwell) : One of my most priced possession. Maxwell is twisted take on **One Shot Frequency Dominant Neighborhood Search**. The scheme provided in the paper is a bit modified to generate fingerprint for an image.
    
  - [**SpiceyDicey**](https://github.com/yash-srivastava19/SpicyDicey) : SpicyDicey is a end to end machine learning project that aims to predicts the number that appears on a dice. All of the work in collecting the data and editing the images has been done individually and from scratch.
    
Here are some of the awesome notebooks üìì I've made on Kaggle(I'm a 2x Kaggle Expert also !!) :

  - [**FC Barcelona is Back!**](https://www.kaggle.com/code/yashsrivastava51213/part1-fc-barcelona-is-back-sports-data-analytics) : Analyzed FC Barcelona‚Äôs LaLiga performance in the 2022-23 season on Kaggle, achieving Bronze Medal and 200+ views apart from receiving recognition from Kaggle.

  - [**BART Pretrainig from Scratch**](https://www.kaggle.com/code/yashsrivastava51213/bart-pretraining-from-scratch) : Developed a BART model from scratch using Huggingface on Shakespeare dataset in a notebook on Kaggle, which received a silver medal and 600+ views.
    
  - [**Tensorflow Recommendation System**](https://www.kaggle.com/code/yashsrivastava51213/tensorflow-recommendation-system-on-movielens) :  Demonstrated on using Tensorflow Recommendation System in a Kaggle notebook that gained bronze medal, and 500+ views.

## Experience üë∑ : 

- **AI Engineer, TurboML**: (Upcoming) Working on building foundational models in India.

- **DevOps Engineer, Strykr.ai**: Primary Backend Engineer of Strykr.ai, where I worked on implementing request caching, response streaming, and async API call which reduced latency by 6 seconds and facilitated deployment migration of the said application from Render to Railway.

- **Project Intern, Solvendo India Private Limited**: Worked with the Machine Learning Team on : a) A production LLM RAG application b) developing time series machine learning models for predict volatility of a stock(Deep Learning Based, GluonTS).
  
- **Research Intern, Indian Institute of Technology-Banaras Hindi University**: Worked under Prof. A.K. Singh on a research project on developing a machine translation system for low resource languages such as Hindi, Bhojpuri, Magahi, Maithali.

- **President, Big Data Analytics and Consulting Cell(National Institute of Technolgy, Warangal)** : Lead the BDACC team for the academic year 2024-2025 after being the member for 2 years in a team that has collaborated in several of the student club events such as Kaggle, Pytorch Workshop and Case study competitions, among other initiatives to develop a community of machine learning enthusiasts in NIT Warangal.
  
- **Executive Member, Research and Development Cell(National Institute of Technolgy, Warangal)**: Part of Undergraduate Research Association team of NIT Warangal which actively takes part in educating and fostering academic growth among undergraduate students.

## About Me üôá‚Äç‚ôÇÔ∏è: 
I am Yashovardhan Srivastava(quite a mouthful, so Yash is good) a paased out undergraduate engineering student from National Institute of Technology, Warangal(2025). From a young age, I have been fascinated by computers. As I grew older, this fascination turned into crush and crush turned into love - and from that moment, I haven't looked back. I believe open source projects has played a significant role in that. They made me fall in love with research, development and much more. Since now I believe I am capable enough to produce some original work, I try to do so from time to time, producing projects that help me deepen my understanding of something I'm interested in. That, for me is the definition of luxury - working on things you like.

All of projects are a result of extreme dedication, meticulousness, and hardwork. Most of them are just random thoughts that I once had, and I thought to myself - **I can build that**.
They do not need recognition, they need discussions. I might have reached a dead end with some of those - but their cycle isn't complete. I have plenty of projects in pipeline, which I hope will be just beautiful as the ones which are already there.

## Career Goals ü•Ö: 
Woah. That's a tough one. There are many things that I like and I feel it is difficult to commit to something. But, there comes a time when we need commit to a field. Balance between exploration and exploitation needs to be made-and for me, that comes from working on research problems. I want to study more, to do things that make me happy.

The place where I come from, this is NOT a trend. We are hard-working, talented people-but we realise very later in life what matters to us. True satisfaction comes from happiness-and that is the purpose of life.

I see myself as a research scientist/research engineer in the near future-specifically in the field of AI, an I want to highlight why this field speaks to me a lot.

Anyone who has studied Engineering(especially in India) will tell how "academically challenging" and "rigorous" the degree is - an I believe it is somewhat justified. Engineers are responsible for building the "lego blocks" on which society stands, and when you work for the greater good of society, you better be the best. I always say, Engineering is a great profession in theory, but(especially here, in India), the adaptation is really not good. I guess my love for engineering did not fade away even after going through this system, so working on "scale up" is something I can see myself working in. It is really fascinating once you get the hold of it.

Another interesting thing that I like is coming up with ideas and test them using the scientific method. The joy of discovering really speaks to the creative side of me, and I would really love if I can make a career in this.   

Those are some of the reasons why I want to be a researcher + engineer. That is, coming up with new ideas, and testing them at various scales of production. This is something that I dream of as of now, but let's see where life takes me.

## What do I look for in a workplace?
I've been workin in AI from some time, and after giving countless interviews and havin chats with founders, here's my few requirements that I look for in a workplace:

- **Innovation over bureaucracy:** In most organization, great ideas get tossed into the bin due to bureaucracy. I feel in a good org, ideas flow freely, and innovation is valued more highly.
  
- **Mission over projects:** An org with a clear mission works in a calculated fashion than an org that hops from project to project. People with high agency tend to thrive in environments where there contributions serve a greater mission.
  
- **Teamwork over individuality:** A talented team from which I can learn is the best, and is something I look for positively. I am by no means expert, and with a talented team I try to learn how to effectively communicate, solve problems and basically manage tasks that are given to me.

Other than that, basic requirements such as good and timely pay, flexibility in working hours, and a sense of respect from the organization would be ideal.

## Proficiency and Interests ‚≠ê :
- Research Interests : Natural Language Processing, Mechanistic Interpretability, AI.
- Building in : Artificial Intelligence Research, Data Science, Natural Language Processing and Machine Learning Research.
- Languages :  Spoken(Hindi, English, Very Basic Spanish), Programming(C, C++,Python, R, Julia)
- Frameworks: Tensorflow, Pytorch, Keras(and anything if given enough time)

## Achievements ü•á
#### Honours
- Promoted as the President of Big Data Analytics and Consulting Cell(National Institute of Technology, Warangal) for the year 2024-2025.
- Received Kaggle Notebook and Dataset Expert with an overall rank of 699 and 573 respectively.
  
- Personal Interests : Football, badminton, avid reader, philosophy connoisseur and writing. 

## Research Papers I Love üìé
In no particular order, I am listing some really awesome research papers that in one way or other have helped me think outside of the box.

 - **[Interpretability in the Wild - IOI Circuit Identification](https://arxiv.org/pdf/2211.00593)** : A very detailed and understandable paper on circuit identification for mechanistic interpretability. Highly recommended if you want to understand how to design your own experiments.

  - **[The Hardware Lottery](https://arxiv.org/pdf/2009.06489.pdf)** : Probably one of my favorite papers till day. The way Sara Hookor explained how AI/ML research should proceed, and how is it going till now is a real eye opener. Highly highly recommend if you want to look at the bigger picture of AI research. 
  
  - **[Scaling Scaling Laws For Board Games](https://arxiv.org/pdf/2104.03113)** : Andy Jones is a genius. This paper explained how we can use shorter experiments to predict outcomes of larger experiments - which are resource heavy. Highly recommend if you want learn how scale up works in real life. 

  - **[Building Machines that Learn and Think for Themselves - Commentary on Lake, Ullman, Tenenbaum, and Gershman](https://arxiv.org/pdf/1604.00289.pdf)** : Not exactly a paper, but this really forced me to think about some things. Definitely recommend this for casual reading.   
      
  - **[A Two-Systems Perspective for Computational Thinking](https://arxiv.org/pdf/2012.03201.pdf)** : This is one of the first papers that I read and it blew my mind. Inspired by the Kahneman's Two Systems Approach of Thinking(Thinking Fast and Slow), this papers presents the cognitive models against which computational thinking can be analyzed and evaluated.

  - **[Attention is all you need](https://arxiv.org/pdf/1706.03762.pdf)** : It's everyone's favourite research paper-and mine too. This was the paper that introduced transformers, and the rest is history. This paper taught me how to communicate your research and how to present your work.
 
  - **[Recsim-A configurable platform for recommender systems](https://arxiv.org/pdf/1909.04847.pdf)** : This opened my eyes. I was in awe when I found out we can use reinforcement learning in recommendation setting. I even emailed the author of the paper thanking and asking him what he thinks whether this will be used in future recommendation systems. Google Research for the WIN.
    
  - **[Improving Low-Resource NMT through Relevance Based Linguistic Features Incorporation](https://aclanthology.org/2020.coling-main.376.pdf)**: This was a really well written and structured paper, which I was able to understand easily, and even used for testing in my internship project.
